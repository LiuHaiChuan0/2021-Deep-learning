# Novel Multimodal Contrast Learning Framework using Zero-Shot Prediction for Abnormal Behavior Recognition

## Overview
This repository hosts the official implementation of VTCL (Visual Text Contrastive Learning), a effective approach crafted for the robust detection of abnormal behaviors in campus environments. VTCL uniquely combines visual and textual modalities through a straightforward integration of cross and multi-frame analysis in the visual branch and an innovative $PW_1PW_2L$ prompting technique in the textual branch. This methodology not only enriches the model's understanding of contextual nuances but also significantly enhances its predictive accuracy and efficiency. VTCL has demonstrated impressive results in both traditional and zero-shot settings, achieving top accuracies on multiple datasets while maintaining competitive computational efficiency. The code will be released as open source.

## Installation


## Usage
The codebase is designed to be user-friendly and is structured for easy integration into existing projects. Detailed usage instructions will be provided for setting up and running the model, including how to load data, train, test, and evaluate the results.
## Train

## Test

## Zero-shot

## Contributing
We welcome contributions from the community. Please refer to our contribution guidelines for more information on how to submit issues, propose bug fixes, or improve the code.

## License
This project is released under the [MIT License](LICENSE).

## Citation
If you find this work useful, please consider citing it in your publications. Citation details are provided in the `CITATION.md` file.

